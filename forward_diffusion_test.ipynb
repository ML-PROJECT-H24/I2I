{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import PIL\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils\n",
    "import torch.distributions\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from diffusers.models import AutoencoderKL\n",
    "\n",
    "from latent_dataset import LatentImageDataset\n",
    "\n",
    "from guassian_noise import GaussianDiffusion, get_named_beta_schedule\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/LATENT_DATASET/LATENT_DATASET'\n",
    "\n",
    "def init_vae():\n",
    "    # https://huggingface.co/stabilityai/sd-vae-ft-mse\n",
    "    model: AutoencoderKL = AutoencoderKL.from_pretrained('stabilityai/sd-vae-ft-mse').to(device)\n",
    "    torch.compile\n",
    "    model = model.eval()\n",
    "    model.train = False\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "vae = init_vae()\n",
    "scale_factor=0.18215 # scale_factor follows DiT and stable diffusion.\n",
    "\n",
    "@torch.no_grad()\n",
    "def encode(x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]: \n",
    "    posterior = vae.encode(x, return_dict=False)[0].parameters\n",
    "    return torch.chunk(posterior, 2, dim=1)    \n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(mean: torch.FloatTensor, logvar: torch.FloatTensor) -> torch.FloatTensor:\n",
    "    std = torch.exp(0.5 * logvar)\n",
    "    z = torch.randn_like(mean)\n",
    "    z = mean + z * std\n",
    "    return z * scale_factor\n",
    "\n",
    "@torch.no_grad()\n",
    "def decode(z) -> torch.Tensor:\n",
    "    x = vae.decode(z / scale_factor, return_dict=False)[0]\n",
    "    x = ((x + 1.0) * 127.5).clamp(0, 255).to(torch.uint8)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LatentImageDataset(DATASET_PATH)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset=dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "def save_image(img, name):\n",
    "  img = img[0]\n",
    "  img = img.cpu()\n",
    "  img = img.permute(1, 2, 0)\n",
    "\n",
    "  PIL.Image.fromarray(img.numpy()).save(f\"{name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timesteps = 1000\n",
    "betas = get_named_beta_schedule(\"linear\", timesteps)\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    betas=betas,\n",
    "    model_mean_type=None, \n",
    "    model_var_type=None,\n",
    "    loss_type=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain next latent image in the dataset\n",
    "\n",
    "mean, logvar = next(iter(dataloader))\n",
    "\n",
    "mean = mean.to(device).to(torch.float32)\n",
    "logvar = logvar.to(device).to(torch.float32)\n",
    "\n",
    "# Sample from the latent space\n",
    "\n",
    "x_0 = sample(mean, logvar)\n",
    "\n",
    "# Save the initial image\n",
    "\n",
    "save_image(decode(x_0), \"sample_0\")\n",
    "\n",
    "# Generate images at different timesteps\n",
    "\n",
    "for t in range(0, 1000, 50):\n",
    "\n",
    "  tt = torch.tensor([t]).to(device) # timestep in torch tensor\n",
    "\n",
    "  # Generate noise\n",
    "\n",
    "  noise = torch.randn(1, 4, 32, 32).to(device)\n",
    "\n",
    "  # Generate image at timestep t\n",
    "\n",
    "  x_t = diffusion.q_sample(x_0, tt, noise)\n",
    "\n",
    "  # Decode the image\n",
    "\n",
    "  decoded = decode(x_t)\n",
    "\n",
    "  # Save the image\n",
    "\n",
    "  save_image(decoded, f\"sample_{t + 50}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
